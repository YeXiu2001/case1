{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CART (Classification and Regression Trees) - DecisionTree Classifier\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 76.190%\n",
      "Confusion Matrix:\n",
      "[[41  2  2]\n",
      " [ 3  0  0]\n",
      " [11  2 23]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82        45\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.92      0.64      0.75        36\n",
      "\n",
      "    accuracy                           0.76        84\n",
      "   macro avg       0.56      0.52      0.52        84\n",
      "weighted avg       0.79      0.76      0.76        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Encode the target variable (Stage) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "    \n",
    "# Split the dataset into training and testing sets\n",
    "test_size = 0.20\n",
    "random_seed = 50\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_seed)\n",
    "\n",
    "# Initialize and train the Decision Tree Classifier with hyperparameters\n",
    "max_depth = 5  # You can adjust this value\n",
    "min_samples_split = 2  # You can adjust this value\n",
    "min_samples_leaf = 1  # You can adjust this value\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "confusion_matrix_dt = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_dt)\n",
    "\n",
    "# Generate the classification report\n",
    "classification_report_dt = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gaussian Naive Bayes\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 73.810%\n",
      "Confusion Matrix:\n",
      "[[46  0  1]\n",
      " [ 2  0  0]\n",
      " [33  0  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72        47\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.67      0.06      0.11        35\n",
      "\n",
      "    accuracy                           0.57        84\n",
      "   macro avg       0.41      0.35      0.27        84\n",
      "weighted avg       0.60      0.57      0.45        84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "  print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 7\n",
    "\n",
    "# Split the dataset into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create a StandardScaler object to standardize the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Standardize the testing data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier\n",
    "model = GaussianNB(priors=None, var_smoothing=1e-9)  # Hyperparameters: priors and var_smoothing\n",
    "\n",
    "# Train the model on the standardized training data\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "result = model.score(X_test_scaled, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "confusion_matrix_nb = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_nb)\n",
    "classification_report_nb = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_nb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient Boosting Machines (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 83.333%\n",
      "Confusion Matrix:\n",
      "[[42  1  4]\n",
      " [ 2  0  0]\n",
      " [ 6  1 28]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87        47\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.88      0.80      0.84        35\n",
      "\n",
      "    accuracy                           0.83        84\n",
      "   macro avg       0.57      0.56      0.57        84\n",
      "weighted avg       0.83      0.83      0.83        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 7\n",
    "\n",
    "# Split the dataset into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create an AdaBoost classifier\n",
    "model = AdaBoostClassifier(n_estimators=50, random_state=seed)\n",
    "# Hyperparameters:\n",
    "# - n_estimators: The number of weak classifiers (base estimators) to train. You can adjust this to control the complexity of the ensemble.\n",
    "# - random_state: The random seed for reproducibility. You can set this to a specific value if you want consistent results.\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate the confusion matrix and classification report\n",
    "confusion_matrix_nb = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_nb)\n",
    "classification_report_nb = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. K-Nearest Neighbors (K-NN)\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 71.429%\n",
      "Confusion Matrix:\n",
      "[[41  0  6]\n",
      " [ 2  0  0]\n",
      " [16  0 19]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77        47\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.76      0.54      0.63        35\n",
      "\n",
      "    accuracy                           0.71        84\n",
      "   macro avg       0.48      0.47      0.47        84\n",
      "weighted avg       0.71      0.71      0.70        84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 7\n",
    "\n",
    "# Split the dataset into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create a K-Nearest Neighbors (K-NN) classifier\n",
    "model = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')\n",
    "# Hyperparameters:\n",
    "# - n_neighbors: The number of nearest neighbors to consider when making predictions. You can adjust this to control the model's sensitivity to local patterns.\n",
    "# - weights: Determines how the neighbors' contributions are weighted (e.g., 'uniform' or 'distance'). You can choose the appropriate weighting strategy.\n",
    "# - algorithm: The algorithm used to compute the nearest neighbors ('auto', 'ball_tree', 'kd_tree', or 'brute'). You can choose the most suitable algorithm based on your data size and structure.\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate the confusion matrix and classification report\n",
    "confusion_matrix_nb = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_nb)\n",
    "classification_report_nb = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Logistic Regression\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 78.571%\n",
      "Confusion Matrix:\n",
      "[[41  0  6]\n",
      " [ 2  0  0]\n",
      " [10  0 25]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82        47\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.81      0.71      0.76        35\n",
      "\n",
      "    accuracy                           0.79        84\n",
      "   macro avg       0.53      0.53      0.53        84\n",
      "weighted avg       0.77      0.79      0.77        84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 7\n",
    "\n",
    "# Split the dataset into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=300, solver='lbfgs', C=1.0)\n",
    "# Hyperparameters:\n",
    "# - max_iter: The maximum number of iterations for the solver to converge. You can adjust this if the model does not converge.\n",
    "# - solver: The algorithm to use for optimization ('lbfgs', 'liblinear', etc.). Choose an appropriate solver for your data and problem.\n",
    "# - C: Inverse of regularization strength. Smaller values increase regularization. You can adjust this to control the trade-off between fitting the data and preventing overfitting.\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate the confusion matrix and classification report\n",
    "confusion_matrix_nb = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_nb)\n",
    "classification_report_nb = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Multi-Layer Perceptron (MLP)\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 73.810%\n",
      "Confusion Matrix:\n",
      "[[41  0  6]\n",
      " [ 2  0  0]\n",
      " [14  0 21]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        47\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.78      0.60      0.68        35\n",
      "\n",
      "    accuracy                           0.74        84\n",
      "   macro avg       0.50      0.49      0.49        84\n",
      "weighted avg       0.73      0.74      0.72        84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 7\n",
    "\n",
    "# Split the dataset into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create an MLP-based model\n",
    "model = MLPClassifier(hidden_layer_sizes=(65, 32), activation='relu', solver='adam', max_iter=200, random_state=seed)\n",
    "# Hyperparameters:\n",
    "# - hidden_layer_sizes: The number of neurons in each hidden layer. You can customize the architecture by adjusting this parameter.\n",
    "# - activation: The activation function used in the hidden layers ('relu', 'tanh', etc.). Choose the appropriate one for your problem.\n",
    "# - solver: The algorithm for weight optimization ('adam', 'lbfgs', etc.). Select the one that works best for your data.\n",
    "# - max_iter: The maximum number of iterations for the solver to converge. You can adjust this if the model does not converge.\n",
    "# - random_state: The random seed for reproducibility. Set this to a specific value for consistent results.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate the confusion matrix and classification report\n",
    "confusion_matrix_nb = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_nb)\n",
    "classification_report_nb = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Perceptron\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 44.048%\n",
      "Confusion Matrix:\n",
      "[[ 3  0 44]\n",
      " [ 0  0  2]\n",
      " [ 1  0 34]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.06      0.12        47\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.42      0.97      0.59        35\n",
      "\n",
      "    accuracy                           0.44        84\n",
      "   macro avg       0.39      0.35      0.24        84\n",
      "weighted avg       0.60      0.44      0.31        84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 7\n",
    "\n",
    "# Split the dataset into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create a Perceptron classifier\n",
    "model = Perceptron(max_iter=200, random_state=seed, eta0=1.0, tol=1e-3)\n",
    "# Hyperparameters:\n",
    "# - max_iter: The maximum number of iterations for the solver to converge. You can adjust this if the model does not converge.\n",
    "# - random_state: The random seed for reproducibility. Set this to a specific value for consistent results.\n",
    "# - eta0: The initial learning rate. You can control the step size for weight updates by adjusting this.\n",
    "# - tol: The tolerance for stopping criterion. The model will stop training when the change in the average loss is smaller than this value.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate the confusion matrix and classification report\n",
    "confusion_matrix_nb = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_nb)\n",
    "classification_report_nb = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Random Forest\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 78.571%\n",
      "Confusion Matrix:\n",
      "[[ 3  0 44]\n",
      " [ 0  0  2]\n",
      " [ 1  0 34]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.06      0.12        47\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.42      0.97      0.59        35\n",
      "\n",
      "    accuracy                           0.44        84\n",
      "   macro avg       0.39      0.35      0.24        84\n",
      "weighted avg       0.60      0.44      0.31        84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 7\n",
    "\n",
    "# Split the dataset into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rfmodel = RandomForestClassifier(n_estimators=100, random_state=seed, max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "# Hyperparameters:\n",
    "# - n_estimators: The number of decision trees in the random forest. Adjust this to control the ensemble size.\n",
    "# - random_state: The random seed for reproducibility. Set this to a specific value for consistent results.\n",
    "# - max_depth: The maximum depth of the decision trees. You can limit tree depth to prevent overfitting.\n",
    "# - min_samples_split: The minimum number of samples required to split a node. Adjust this to control tree node splitting.\n",
    "# - min_samples_leaf: The minimum number of samples required in a leaf node. You can adjust this to control tree leaf size.\n",
    "\n",
    "# Train the model\n",
    "rfmodel.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "result = rfmodel.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate the confusion matrix and classification report\n",
    "confusion_matrix_nb = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_nb)\n",
    "classification_report_nb = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Support Vector Machines (SVM)\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Accuracy: 78.571%\n",
      "Confusion Matrix:\n",
      "[[41  1  5]\n",
      " [ 1  1  0]\n",
      " [10  1 24]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        47\n",
      "           1       0.33      0.50      0.40         2\n",
      "           2       0.83      0.69      0.75        35\n",
      "\n",
      "    accuracy                           0.79        84\n",
      "   macro avg       0.65      0.69      0.66        84\n",
      "weighted avg       0.79      0.79      0.79        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 7\n",
    "\n",
    "# Split the dataset into test and train\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Create an SVM classifier\n",
    "model = SVC(kernel='linear', C=1.0, random_state=seed)\n",
    "# Hyperparameters:\n",
    "# - kernel: The type of kernel to use ('linear', 'poly', 'rbf', etc.). Choose the appropriate kernel for your problem.\n",
    "# - C: The regularization parameter. Smaller values increase regularization. You can adjust this to control the trade-off between fitting the data and preventing overfitting.\n",
    "# - random_state: The random seed for reproducibility. Set this to a specific value for consistent results.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# Generate the confusion matrix and classification report\n",
    "confusion_matrix_nb = confusion_matrix(Y_test, model.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_nb)\n",
    "classification_report_nb = classification_report(Y_test, model.predict(X_test))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
