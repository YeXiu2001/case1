{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CART (Classification and Regression Trees) - DecisionTree Classifier\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Fold 1 - Accuracy: 0.762\n",
      "Fold 1 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82        45\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.92      0.64      0.75        36\n",
      "\n",
      "    accuracy                           0.76        84\n",
      "   macro avg       0.56      0.52      0.52        84\n",
      "weighted avg       0.79      0.76      0.76        84\n",
      "\n",
      "Fold 2 - Accuracy: 0.714\n",
      "Fold 2 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80        46\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.83      0.56      0.67        34\n",
      "\n",
      "    accuracy                           0.71        84\n",
      "   macro avg       0.52      0.48      0.49        84\n",
      "weighted avg       0.73      0.71      0.71        84\n",
      "\n",
      "Fold 3 - Accuracy: 0.702\n",
      "Fold 3 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81        46\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.73      0.55      0.63        29\n",
      "\n",
      "    accuracy                           0.70        84\n",
      "   macro avg       0.48      0.50      0.48        84\n",
      "weighted avg       0.64      0.70      0.66        84\n",
      "\n",
      "Fold 4 - Accuracy: 0.783\n",
      "Fold 4 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        43\n",
      "           1       0.25      0.20      0.22         5\n",
      "           2       0.80      0.69      0.74        35\n",
      "\n",
      "    accuracy                           0.78        83\n",
      "   macro avg       0.62      0.61      0.61        83\n",
      "weighted avg       0.78      0.78      0.78        83\n",
      "\n",
      "Fold 5 - Accuracy: 0.843\n",
      "Fold 5 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        52\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.82      0.85      0.84        27\n",
      "\n",
      "    accuracy                           0.84        83\n",
      "   macro avg       0.58      0.59      0.58        83\n",
      "weighted avg       0.83      0.84      0.84        83\n",
      "\n",
      "\n",
      "Average Accuracy: 0.761\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Initialize the Decision Tree Classifier with hyperparameters\n",
    "max_depth = 5  # You can adjust this value\n",
    "min_samples_split = 2  # You can adjust this value\n",
    "min_samples_leaf = 1  # You can adjust this value\n",
    "random_seed = 50\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# Use K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=random_seed, shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Evaluate the accuracy for each fold\n",
    "    accuracy = model.score(X_test, Y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Fold {fold} - Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    # Generate the classification report for each fold\n",
    "    classification_report_fold = classification_report(Y_test, model.predict(X_test))\n",
    "    print(f\"Fold {fold} - Classification Report:\")\n",
    "    print(classification_report_fold)\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(\"\\nAverage Accuracy:\", f\"{average_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gaussian Naive Bayes\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "Fold 1 - Accuracy: 0.738\n",
      "Fold 1 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81        47\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.83      0.57      0.68        35\n",
      "\n",
      "    accuracy                           0.74        84\n",
      "   macro avg       0.52      0.49      0.50        84\n",
      "weighted avg       0.76      0.74      0.73        84\n",
      "\n",
      "Fold 2 - Accuracy: 0.690\n",
      "Fold 2 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.79        42\n",
      "           1       0.25      0.08      0.12        12\n",
      "           2       0.78      0.60      0.68        30\n",
      "\n",
      "    accuracy                           0.69        84\n",
      "   macro avg       0.57      0.54      0.53        84\n",
      "weighted avg       0.66      0.69      0.65        84\n",
      "\n",
      "Fold 3 - Accuracy: 0.750\n",
      "Fold 3 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        48\n",
      "           1       0.33      0.33      0.33         3\n",
      "           2       0.79      0.58      0.67        33\n",
      "\n",
      "    accuracy                           0.75        84\n",
      "   macro avg       0.63      0.60      0.61        84\n",
      "weighted avg       0.75      0.75      0.74        84\n",
      "\n",
      "Fold 4 - Accuracy: 0.663\n",
      "Fold 4 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.76        42\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.82      0.50      0.62        36\n",
      "\n",
      "    accuracy                           0.66        83\n",
      "   macro avg       0.49      0.46      0.46        83\n",
      "weighted avg       0.69      0.66      0.65        83\n",
      "\n",
      "Fold 5 - Accuracy: 0.711\n",
      "Fold 5 - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80        53\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.74      0.52      0.61        27\n",
      "\n",
      "    accuracy                           0.71        83\n",
      "   macro avg       0.50      0.46      0.47        83\n",
      "weighted avg       0.73      0.71      0.71        83\n",
      "\n",
      "\n",
      "Average Accuracy: 0.710\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the random seed\n",
    "seed = 7  # You can adjust this value\n",
    "# Set the number of folds for K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create a StandardScaler object to standardize the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Initialize Gaussian Naive Bayes classifier\n",
    "model = GaussianNB(priors=None, var_smoothing=1e-9)  # Hyperparameters: priors and var_smoothing\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Standardize the training data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Standardize the testing data\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train the model on the standardized training data\n",
    "    model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    # Evaluate the accuracy for each fold\n",
    "    result = model.score(X_test_scaled, Y_test)\n",
    "    accuracies.append(result)\n",
    "    print(f\"Fold {fold} - Accuracy: {result:.3f}\")\n",
    "\n",
    "    # Generate the classification report for each fold\n",
    "    classification_report_fold = classification_report(Y_test, model.predict(X_test_scaled))\n",
    "    print(f\"Fold {fold} - Classification Report:\")\n",
    "    print(classification_report_fold)\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(\"\\nAverage Accuracy:\", f\"{average_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient Boosting Machines (AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "\n",
      "Fold 1 - Accuracy: 0.833\n",
      "\n",
      "Fold 2 - Accuracy: 0.702\n",
      "\n",
      "Fold 3 - Accuracy: 0.750\n",
      "\n",
      "Fold 4 - Accuracy: 0.783\n",
      "\n",
      "Fold 5 - Accuracy: 0.759\n",
      "No classification reports available.\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the random seed\n",
    "seed = 7  # You can adjust this value\n",
    "# Set the number of folds for K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create an AdaBoost classifier\n",
    "model = AdaBoostClassifier(n_estimators=50, random_state=seed)\n",
    "# Hyperparameters:\n",
    "# - n_estimators: The number of weak classifiers (base estimators) to train. You can adjust this to control the complexity of the ensemble.\n",
    "# - random_state: The random seed for reproducibility. You can set this to a specific value if you want consistent results.\n",
    "\n",
    "# Initialize lists to store accuracy and classification reports for each fold\n",
    "accuracies = []\n",
    "classification_reports = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Evaluate the accuracy for each fold\n",
    "    result = model.score(X_test, Y_test)\n",
    "    accuracies.append(result)\n",
    "    print(f\"\\nFold {fold} - Accuracy: {result:.3f}\")\n",
    "\n",
    "    # Generate the classification report for each fold\n",
    "    y_pred = model.predict(X_test)\n",
    "    classification_report_fold = precision_recall_fscore_support(Y_test, y_pred, average='weighted')\n",
    "    if None not in classification_report_fold:\n",
    "        classification_reports.append(classification_report_fold)\n",
    "        print(f\"Fold {fold} - Classification Report:\")\n",
    "        print(classification_report(Y_test, y_pred, target_names=label_mapping.keys()))\n",
    "\n",
    "# Check if there are any performance metrics in the list\n",
    "if classification_reports:\n",
    "    # Calculate and print the average accuracy\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    print(\"\\nAverage Accuracy:\", f\"{average_accuracy:.3f}\")\n",
    "\n",
    "    # Print the average precision, recall, F1-score, and support over all folds\n",
    "    average_metrics = np.mean([np.array(report) for report in classification_reports], axis=0)\n",
    "    precision, recall, f1, support = average_metrics[:4]\n",
    "\n",
    "    print(\"\\nAverage Metrics:\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "    print(f\"Support: {support:.3f}\")\n",
    "else:\n",
    "    print(\"No classification reports available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. K-Nearest Neighbors (K-NN)\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "\n",
      "Fold 1 - Precision: 0.729\n",
      "\n",
      "Fold 2 - Precision: 0.627\n",
      "\n",
      "Fold 3 - Precision: 0.685\n",
      "\n",
      "Fold 4 - Precision: 0.667\n",
      "\n",
      "Fold 5 - Precision: 0.727\n",
      "\n",
      "Average Precision: 0.687\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the number of folds for K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create a K-Nearest Neighbors (K-NN) classifier\n",
    "model = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')\n",
    "\n",
    "# Initialize lists to store precision and support for each fold\n",
    "precision_list = []\n",
    "support_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Generate the classification report for each fold\n",
    "    metrics_fold = precision_recall_fscore_support(Y_test, model.predict(X_test), zero_division=1, average='weighted')\n",
    "    precision_list.append(metrics_fold[0])\n",
    "\n",
    "    # Calculate the support separately\n",
    "    support_fold = np.sum(metrics_fold[3])\n",
    "    support_list.append(support_fold)\n",
    "\n",
    "    print(f\"\\nFold {fold} - Precision: {metrics_fold[0]:.3f}\")\n",
    "\n",
    "# Check if there are any performance metrics in the list\n",
    "if precision_list:\n",
    "    # Print the average precision over all folds\n",
    "    average_precision = np.mean(precision_list)\n",
    "    print(\"\\nAverage Precision:\", f\"{average_precision:.3f}\")\n",
    "else:\n",
    "    print(\"No precision values available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Logistic Regression\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "\n",
      "Fold 1 - Precision: 0.839\n",
      "\n",
      "Fold 2 - Precision: 0.628\n",
      "\n",
      "Fold 3 - Precision: 0.827\n",
      "\n",
      "Fold 4 - Precision: 0.771\n",
      "\n",
      "Fold 5 - Precision: 0.797\n",
      "\n",
      "Average Precision:\n",
      "0.772\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for this example\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the number of folds for K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create a Logistic Regression model with increased max_iter\n",
    "model = LogisticRegression(max_iter=5000, solver='lbfgs', C=1.0)  # Increased max_iter\n",
    "\n",
    "# Initialize lists to store precision for each fold\n",
    "precision_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Calculate precision for each fold\n",
    "    precision_fold = precision_score(Y_test, model.predict(X_test), average='weighted')\n",
    "    print(f\"\\nFold {fold} - Precision: {precision_fold:.3f}\")\n",
    "\n",
    "    # Append precision to the list\n",
    "    precision_list.append(precision_fold)\n",
    "\n",
    "# Check if there are any precision values in the list\n",
    "if precision_list:\n",
    "    # Print the average precision over all folds\n",
    "    average_precision = np.mean(precision_list)\n",
    "    print(\"\\nAverage Precision:\")\n",
    "    print(f\"{average_precision:.3f}\")\n",
    "else:\n",
    "    print(\"No precision values available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Multi-Layer Perceptron (MLP)\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "\n",
      "Fold 1 - Precision: 0.720\n",
      "\n",
      "Fold 2 - Precision: 0.487\n",
      "\n",
      "Fold 3 - Precision: 0.748\n",
      "\n",
      "Fold 4 - Precision: 0.497\n",
      "\n",
      "Fold 5 - Precision: 0.718\n",
      "\n",
      "Average Precision:\n",
      "0.634\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for this example\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the number of folds for K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create an MLP-based model\n",
    "model = MLPClassifier(hidden_layer_sizes=(65, 32), activation='relu', solver='adam', max_iter=200, random_state=seed)\n",
    "\n",
    "# Initialize lists to store precision and support for each fold\n",
    "precision_list = []\n",
    "support_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Generate classification report for each fold\n",
    "    report_fold = classification_report(Y_test, model.predict(X_test), output_dict=True)\n",
    "    \n",
    "    # Extract precision and support from the report\n",
    "    precision_list.append(report_fold['weighted avg']['precision'])\n",
    "    support_fold = np.sum(report_fold['weighted avg']['support'])\n",
    "    support_list.append(support_fold)\n",
    "\n",
    "    print(f\"\\nFold {fold} - Precision: {report_fold['weighted avg']['precision']:.3f}\")\n",
    "\n",
    "# Check if there are any precision values in the list\n",
    "if precision_list:\n",
    "    # Print the average precision over all folds\n",
    "    average_precision = np.average(precision_list, weights=support_list)\n",
    "    print(\"\\nAverage Precision:\")\n",
    "    print(f\"{average_precision:.3f}\")\n",
    "else:\n",
    "    print(\"No precision values available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Perceptron\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "\n",
      "Fold 1 - Precision: 0.686\n",
      "\n",
      "Fold 2 - Precision: 0.579\n",
      "\n",
      "Fold 3 - Precision: 0.758\n",
      "\n",
      "Fold 4 - Precision: 0.639\n",
      "\n",
      "Fold 5 - Precision: 0.706\n",
      "\n",
      "Average Precision:\n",
      "0.673\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for this example\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the number of folds for K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create a Perceptron classifier\n",
    "model = Perceptron(max_iter=200, random_state=seed, eta0=1.0, tol=1e-3)\n",
    "\n",
    "# Initialize lists to store precision and support for each fold\n",
    "precision_list = []\n",
    "support_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Generate classification report for each fold\n",
    "    report_fold = classification_report(Y_test, model.predict(X_test), output_dict=True)\n",
    "    \n",
    "    # Extract precision and support from the report\n",
    "    precision_list.append(report_fold['weighted avg']['precision'])\n",
    "    support_fold = np.sum(report_fold['weighted avg']['support'])\n",
    "    support_list.append(support_fold)\n",
    "\n",
    "    print(f\"\\nFold {fold} - Precision: {report_fold['weighted avg']['precision']:.3f}\")\n",
    "\n",
    "# Check if there are any precision values in the list\n",
    "if precision_list:\n",
    "    # Print the average precision over all folds\n",
    "    average_precision = np.average(precision_list, weights=support_list)\n",
    "    print(\"\\nAverage Precision:\")\n",
    "    print(f\"{average_precision:.3f}\")\n",
    "else:\n",
    "    print(\"No precision values available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Random Forest\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "\n",
      "Fold 1 - Precision: 0.762\n",
      "\n",
      "Fold 2 - Precision: 0.640\n",
      "\n",
      "Fold 3 - Precision: 0.840\n",
      "\n",
      "Fold 4 - Precision: 0.727\n",
      "\n",
      "Fold 5 - Precision: 0.829\n",
      "\n",
      "Average Precision:\n",
      "0.759\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the number of folds for K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rfmodel = RandomForestClassifier(n_estimators=100, random_state=seed, max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "# Initialize lists to store precision and support for each fold\n",
    "precision_list = []\n",
    "support_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    rfmodel.fit(X_train, Y_train)\n",
    "\n",
    "    # Generate classification report for each fold\n",
    "    report_fold = classification_report(Y_test, rfmodel.predict(X_test), output_dict=True)\n",
    "    \n",
    "    # Extract precision and support from the report\n",
    "    precision_list.append(report_fold['weighted avg']['precision'])\n",
    "    support_fold = np.sum(report_fold['weighted avg']['support'])\n",
    "    support_list.append(support_fold)\n",
    "\n",
    "    print(f\"\\nFold {fold} - Precision: {report_fold['weighted avg']['precision']:.3f}\")\n",
    "\n",
    "# Check if there are any precision values in the list\n",
    "if precision_list:\n",
    "    # Print the average precision over all folds\n",
    "    average_precision = np.average(precision_list, weights=support_list)\n",
    "    print(\"\\nAverage Precision:\")\n",
    "    print(f\"{average_precision:.3f}\")\n",
    "else:\n",
    "    print(\"No precision values available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Support Vector Machines (SVM)\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "Label: C, Numerical Value: 0\n",
      "Label: CL, Numerical Value: 1\n",
      "Label: D, Numerical Value: 2\n",
      "\n",
      "Fold 1 - Precision: 0.705\n",
      "\n",
      "Fold 2 - Precision: 0.484\n",
      "\n",
      "Fold 3 - Precision: 0.685\n",
      "\n",
      "Fold 4 - Precision: 0.667\n",
      "\n",
      "Fold 5 - Precision: 0.691\n",
      "\n",
      "Average Precision: 0.646\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "filename = './cirrhosis.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = dataframe.drop('Status', axis=1)\n",
    "Y = dataframe['Status']\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "# Encode the target variable (Status) using label encoding\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "# Display the mapping of labels to numerical values\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\")\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label: {label}, Numerical Value: {value}\")\n",
    "\n",
    "# Set the number of folds for K-fold Cross Validation\n",
    "num_folds = 5  # You can adjust the number of folds\n",
    "kf = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create a K-Nearest Neighbors (K-NN) classifier\n",
    "model = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto')\n",
    "\n",
    "# Initialize lists to store precision and support for each fold\n",
    "precision_list = []\n",
    "support_list = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, Y), 1):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Generate the classification report for each fold\n",
    "    report_fold = classification_report(Y_test, model.predict(X_test), output_dict=True)\n",
    "    \n",
    "    # Extract precision and support from the report\n",
    "    precision_list.append(report_fold['weighted avg']['precision'])\n",
    "    support_fold = np.sum(report_fold['weighted avg']['support'])\n",
    "    support_list.append(support_fold)\n",
    "\n",
    "    print(f\"\\nFold {fold} - Precision: {report_fold['weighted avg']['precision']:.3f}\")\n",
    "\n",
    "# Check if there are any precision values in the list\n",
    "if precision_list:\n",
    "    # Print the average precision over all folds\n",
    "    average_precision = np.average(precision_list, weights=support_list)\n",
    "    print(\"\\nAverage Precision:\", f\"{average_precision:.3f}\")\n",
    "else:\n",
    "    print(\"No precision values available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
